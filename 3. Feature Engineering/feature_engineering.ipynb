{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8292be35",
   "metadata": {},
   "source": [
    "# Feature Engineering for Insurance Fraud Detection\n",
    "\n",
    "This notebook builds on the cleaned dataset and prepares it for machine learning by:\n",
    "\n",
    "- Extracting meaningful **time based features** from `incident_date`\n",
    "- Creating a custom **fraud signal** (`fraud_weight`)\n",
    "- Applying **One-Hot Encoding** to key categorical variables\n",
    "- Saving the final dataset as a model ready CSV for training\n",
    "\n",
    "These steps are crucial for improving model performance and interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3becfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# Define project directory path\n",
    "project_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Load cleaned dataset from ETL output\n",
    "clean_data_path = os.path.join(project_dir, 'data', 'processed', 'cleaned_insurance_claims.csv')\n",
    "df = pd.read_csv(clean_data_path)\n",
    "\n",
    "# Confirm successful load\n",
    "print(\"Loaded cleaned dataset with shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143cdde9",
   "metadata": {},
   "source": [
    "## 1. Create Time Based Features\n",
    "\n",
    "If the `incident_date` column exists, extract the following features:\n",
    "\n",
    "- **`incident_year`** – Year of the incident (e.g., 2014)\n",
    "- **`incident_month`** – Month of the incident (1–12)\n",
    "- **`incident_dayofweek`** – Day of the week (0 = Monday, 6 = Sunday)\n",
    "- **`incident_day`** – Day of the month (1–31)\n",
    "- **`incident_is_weekend`** – Binary flag: 1 if the incident occurred on a weekend (Saturday/Sunday), 0 otherwise\n",
    "\n",
    "> These derived features capture seasonal, weekly, and behavioral patterns in claim timings, which may be linked to fraud likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f206f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and convert 'incident_date' column\n",
    "if 'incident_date' in df.columns:\n",
    "    df['incident_date'] = pd.to_datetime(df['incident_date'], errors='coerce')\n",
    "\n",
    "    # Display missing/invalid date conversions\n",
    "    num_missing_dates = df['incident_date'].isna().sum()\n",
    "    display(Markdown(f\"**Missing or invalid incident_date rows:** {num_missing_dates}\"))\n",
    "\n",
    "    # Drop rows with invalid dates (optional - already cleaned in ETL but I like to double check)\n",
    "    df = df.dropna(subset=['incident_date'])\n",
    "\n",
    "    # Extract parts of date\n",
    "    df['incident_year'] = df['incident_date'].dt.year\n",
    "    df['incident_month'] = df['incident_date'].dt.month\n",
    "    df['incident_dayofweek'] = df['incident_date'].dt.dayofweek\n",
    "    df['incident_day'] = df['incident_date'].dt.day\n",
    "\n",
    "    # Create a weekend flag\n",
    "    df['incident_is_weekend'] = df['incident_dayofweek'].isin([5, 6]).astype(int)\n",
    "    print(\"Time-based features created:\", ['incident_year', 'incident_month', 'incident_dayofweek', 'incident_day', 'incident_is_weekend'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3ce66e",
   "metadata": {},
   "source": [
    "## 3. Create a Fraud Signal Feature\n",
    "\n",
    "This feature captures interaction between the monetary value of a claim and its risk score.\n",
    "Higher `fraud_weight` values may correlate with suspicious high risk, high value claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd9d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new feature that combines claim amount with risk\n",
    "df['fraud_weight'] = df['total_claim_amount'] * df['risk_score']\n",
    "\n",
    "# Preview to verify\n",
    "df[['total_claim_amount', 'risk_score', 'fraud_weight']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66bf492",
   "metadata": {},
   "source": [
    "## 4. One-Hot Encode Key Categorical Features\n",
    "\n",
    "To prepare for machine learning, I converted selected categorical features into binary variables.\n",
    "I used `drop_first=True` to avoid multicollinearity in linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b98a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical columns to encode (from EDA insights)\n",
    "categorical_cols = ['incident_type', 'collision_type', 'police_report_available']\n",
    "\n",
    "# Perform one-hot encoding\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Confirm new shape\n",
    "print(\"One-hot encoding complete. New dataset shape:\", df_encoded.shape)\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ba0256",
   "metadata": {},
   "source": [
    "## 5. Save Engineered Dataset\n",
    "\n",
    "Save the final dataset to the `data/features/` folder. This will be used in the next step: `model_training.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f237d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output path\n",
    "engineered_dir = os.path.join(project_dir, \"data\", \"features\")\n",
    "os.makedirs(engineered_dir, exist_ok=True)  # This will create the directory if it doesn't exist\n",
    "\n",
    "# Save to CSV\n",
    "feature_file = os.path.join(engineered_dir, \"engineered_insurance_claims.csv\")\n",
    "df_encoded.to_csv(feature_file, index=False)\n",
    "print(f\"Feature dataset saved to: {feature_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
