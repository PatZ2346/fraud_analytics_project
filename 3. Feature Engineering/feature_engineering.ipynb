{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8292be35",
   "metadata": {},
   "source": [
    "# Feature Engineering for Insurance Fraud Detection\n",
    "\n",
    "This notebook builds on the cleaned dataset and prepares it for modeling by:\n",
    "\n",
    "- Extracting meaningful **time-based features** from `incident_date`\n",
    "- Creating a custom **fraud risk signal** (`fraud_weight`)\n",
    "- Applying **One-Hot Encoding** to relevant categorical variables\n",
    "- Saving the transformed dataset as a **model-ready CSV** for training and evaluation\n",
    "\n",
    "This step is critical for improving model performance and interpretability in fraud detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3becfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143cdde9",
   "metadata": {},
   "source": [
    "## 1. Create Time-Based Features\n",
    "\n",
    "If the `incident_date` column exists, extract the following features:\n",
    "\n",
    "- **`incident_year`** – Year of the incident (e.g., 2014)\n",
    "- **`incident_month`** – Month of the incident (1–12)\n",
    "- **`incident_dayofweek`** – Day of the week (0 = Monday, 6 = Sunday)\n",
    "- **`incident_day`** – Day of the month (1–31)\n",
    "- **`incident_is_weekend`** – Binary flag: 1 if the incident occurred on a weekend (Saturday/Sunday), 0 otherwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f206f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If 'incident_date' exists, convert and extract date-related features\n",
    "if 'incident_date' in df.columns:\n",
    "    df['incident_date'] = pd.to_datetime(df['incident_date'], errors='coerce')\n",
    "\n",
    "    # Extract parts of the date into new columns\n",
    "    df['incident_year'] = df['incident_date'].dt.year\n",
    "    df['incident_month'] = df['incident_date'].dt.month\n",
    "    df['incident_dayofweek'] = df['incident_date'].dt.dayofweek\n",
    "    df['incident_day'] = df['incident_date'].dt.day\n",
    "\n",
    "    # Binary feature: 1 if incident was on weekend (Saturday or Sunday), else 0\n",
    "    df['incident_is_weekend'] = df['incident_dayofweek'].isin([5, 6]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3ce66e",
   "metadata": {},
   "source": [
    "## 2. Add Interaction Feature\n",
    "\n",
    "Multiply `total_claim_amount` by `risk_score` to estimate `fraud_weight`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd9d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply claim amount by risk score to create a weighted fraud risk metric\n",
    "df['fraud_weight'] = df['total_claim_amount'] * df['risk_score']\n",
    "\n",
    "# Preview key fraud-related features\n",
    "df[['total_claim_amount', 'risk_score', 'fraud_weight']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66bf492",
   "metadata": {},
   "source": [
    "## 3. Encode Categorical Features\n",
    "\n",
    "Apply **One-Hot Encoding** to convert selected categorical columns into binary indicator (dummy) variables:\n",
    "\n",
    "- Encoded columns: `incident_type`, `collision_type`, `police_report_available`\n",
    "- Dropped the first category from each to avoid multicollinearity (`drop_first=True`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b98a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical columns to encode (from EDA insight)\n",
    "categorical_cols = ['incident_type', 'collision_type', 'police_report_available']\n",
    "\n",
    "# Apply one-hot encoding, dropping the first level to avoid multicollinearity\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "print(\"One-hot encoding complete. New shape:\", df_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ba0256",
   "metadata": {},
   "source": [
    "## 4. Save Final Feature Dataset\n",
    "\n",
    "Save the fully transformed dataset including engineered features and encoded variables as a CSV file.\n",
    "This dataset will serve as the input for the upcoming model training and evaluation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f237d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder path to save feature set\n",
    "engineered_dir = os.path.join(project_dir, \"data\", \"features\")\n",
    "os.makedirs(engineered_dir, exist_ok=True)  # Create if it doesn't exist\n",
    "\n",
    "# Save final engineered feature set to CSV\n",
    "feature_file = os.path.join(engineered_dir, \"engineered_insurance_claims.csv\")\n",
    "df_encoded.to_csv(feature_file, index=False)\n",
    "print(f\"Feature dataset saved to:\\n{feature_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
