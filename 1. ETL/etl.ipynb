{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89ed362b",
   "metadata": {},
   "source": [
    "# ETL Pipeline for Insurance Fraud Detection\n",
    "\n",
    "This notebook implements a structured **Extract, Transform, Load (ETL)** pipeline on raw insurance claims data I foundd on kaggle, link here `https://www.kaggle.com/datasets/antopravinjohnbosco/auto-insurance-claims-fraud-detection?resource=download`.  \n",
    "The goal is to clean and prepare the dataset for accurate fraud detection analysis and subsequently load the processed data into a **PostgreSQL** database for efficient querying.\n",
    "\n",
    "### Pipeline Overview:\n",
    "- Load raw insurance claims data from CSV\n",
    "- Conduct thorough data integrity and quality checks\n",
    "- Handle missing and inconsistent data with appropriate transformations\n",
    "- Engineer key features to support fraud detection modeling\n",
    "- Save the cleaned dataset as a reusable **CSV**\n",
    "- Load cleaned data into a PostgreSQL table (`insurance_claims`)\n",
    "- Run SQL queries to validate data loading and summarize fraud occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40960bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import pandas as pd                       # For data manipulation and cleaning\n",
    "import os                                 # For managing file paths\n",
    "from sqlalchemy import create_engine      # For database connection to PostgreSQL\n",
    "from dotenv import load_dotenv            # For loading environment variables from .env file\n",
    "load_dotenv()                             # Load environment variables from .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2279c88",
   "metadata": {},
   "source": [
    "## 1. Define File Paths & PostgreSQL Connection\n",
    "\n",
    "Set up input/output file locations and connect to my **PostgreSQL** database using **SQLAlchemy**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21623a7",
   "metadata": {},
   "source": [
    "### Define File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5adf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base project directory\n",
    "project_dir = r\"C:\\Users\\Cloud\\OneDrive\\Desktop\\Fraud_Analytics_Project\"\n",
    "\n",
    "# Define path to the raw insurance claims CSV dataset\n",
    "dataset_path = os.path.join(project_dir, \"dataset\", \"insurance_fraud_claims.csv\")\n",
    "\n",
    "# Define directory to save cleaned data outputs\n",
    "cleaned_dir = os.path.join(project_dir, \"data\", \"cleaned\")\n",
    "os.makedirs(cleaned_dir, exist_ok=True)\n",
    "\n",
    "# Define path to save cleaned dataset\n",
    "cleaned_file = os.path.join(cleaned_dir, \"cleaned_insurance_claims.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d1e24",
   "metadata": {},
   "source": [
    "### PostgreSQL Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9731c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PostgreSQL credentials, mine is stored in a .env file\n",
    "pg_user = os.getenv(\"PG_USER\")              # Your PostgreSQL username\n",
    "pg_password = os.getenv(\"PG_PASSWORD\")      # Your password\n",
    "pg_host = os.getenv(\"PG_HOST\")              # Host where PostgreSQL is running (usually localhost)\n",
    "pg_port = os.getenv(\"PG_PORT\")              # Default PostgreSQL port\n",
    "pg_dbname = os.getenv(\"PG_DBNAME\")          # The database you've created in pgAdmin\n",
    "\n",
    "# Safety check to ensure no credentials are missing\n",
    "required_env_vars = [pg_user, pg_password, pg_host, pg_port, pg_dbname]\n",
    "if any(v is None for v in required_env_vars):\n",
    "    raise ValueError(\"One or more environment variables are missing. Check your .env file.\")\n",
    "\n",
    "# Establish connection engine to PostgreSQL database for data loading and querying\n",
    "engine = create_engine(\n",
    "    f\"postgresql+psycopg2://{pg_user}:{pg_password}@{pg_host}:{pg_port}/{pg_dbname}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877a7013",
   "metadata": {},
   "source": [
    "## 2. Load Raw Insurance Claims Dataset\n",
    "\n",
    "Read the original dataset into a `pandas` DataFrame and preview its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b068be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw insurance claims data into a pandas DataFrame\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Preview and display first few rows of DataFrame structure\n",
    "print(\"Raw data loaded. Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c665ec",
   "metadata": {},
   "source": [
    "## 3. Replace Placeholder Values with Standard Missing Marker\n",
    "\n",
    "Many datasets use placeholders like `\"?\"`, `\"unknown\"`, `\"n/a\"`, or `\"missing\"` to indicate missing or unclear data.  \n",
    "To ensure consistent and accurate analysis, I replaced these placeholders with `pandas` standard missing value marker (`pd.NA`).  \n",
    "\n",
    "This helps downstream processes correctly recognize and handle missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec792585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of placeholder values commonly used for missing data\n",
    "placeholders = ['?', 'unknown', 'n/a', 'missing']\n",
    "\n",
    "# Replace all such placeholders with pandas standard missing value marker pd.NA\n",
    "df.replace(placeholders, pd.NA, inplace=True)\n",
    "print(\"Placeholder values like '?' replaced with pd.NA.\\n\")\n",
    "\n",
    "# Normalize 'fraud_reported' for consistent validation and mapping\n",
    "if 'fraud_reported' in df.columns:\n",
    "    df['fraud_reported'] = df['fraud_reported'].astype(str).str.strip().str.upper()\n",
    "    print(\"Normalized 'fraud_reported' values to uppercase and stripped whitespace.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b378fca",
   "metadata": {},
   "source": [
    "## 4. Normalize All String Columns For Uniformity\n",
    "\n",
    "Here I need to standardize string based fields to ensure consistency across the dataset. \n",
    "String values (like `'yes'`, `'Yes'`, `' YES '`) may represent the same category but appear different to a computer. This step ensures all string columns are uniformly formatted for reliable processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192bcb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize all string and object columns to ensure consistent formatting\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = df[col].astype(str).str.strip().str.upper()\n",
    "    \n",
    "print(\"Normalized all string columns: stripped whitespace and converted text to uppercase.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7990ae",
   "metadata": {},
   "source": [
    "## 5. Data Integrity and Validity Checks\n",
    "\n",
    "In this step, I have performed essential checks to ensure the dataset's quality and reliability before analysis, including:\n",
    "\n",
    "- Confirming the overall shape and structure of the dataset  \n",
    "- Identifying any duplicate records  \n",
    "- Summarizing missing values and their prevalence  \n",
    "- Verifying data types for each column  \n",
    "- Reviewing unique values in categorical columns to detect anomalies or typos  \n",
    "- Validating that key columns, such as `fraud_reported`, contain only expected values `\"Y\" or \"N\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3bfbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Integrity Check\n",
    "print(\"Initial Integrity Checks\")\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "\n",
    "# 1. Column names and data types\n",
    "print(\"\\nColumn Names and Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# 2. Check for duplicate rows\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\nDuplicate rows: {duplicates}\")\n",
    "\n",
    "# 3. Check for missing values\n",
    "missing = df.isnull().sum()\n",
    "missing_percent = (missing / len(df) * 100).round(2)\n",
    "print(\"\\nMissing Values:\")\n",
    "print(pd.DataFrame({'Missing Count': missing, 'Percent': missing_percent}).loc[missing > 0])\n",
    "\n",
    "# 4. Unique values in categorical columns\n",
    "cat_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "print(\"\\nUnique values in categorical columns:\")\n",
    "for col in cat_cols:\n",
    "    print(f\"{col}: {df[col].nunique()} unique values\")\n",
    "    print(f\"  → {df[col].unique()[:5]} ...\")  # Display sample of unique values to detect any irregular categories\n",
    "\n",
    "# 5. Check for expected column presence\n",
    "expected_cols = ['fraud_reported', 'incident_type', 'total_claim_amount']\n",
    "missing_cols = [col for col in expected_cols if col not in df.columns]\n",
    "if missing_cols:\n",
    "    print(f\"\\nMissing expected columns: {missing_cols}\")\n",
    "else:\n",
    "    print(\"\\nAll expected columns are present.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daae65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that 'fraud_reported' contains only expected values ('Y' or 'N') to prevent downstream errors\n",
    "if 'fraud_reported' in df.columns:\n",
    "    valid_fraud_values = set(df['fraud_reported'].dropna().unique())\n",
    "    if not valid_fraud_values.issubset({'Y', 'N'}):\n",
    "        print(f\"Invalid values found in 'fraud_reported': {valid_fraud_values}\")\n",
    "    else:\n",
    "        print(\"'fraud_reported' column contains only 'Y' and 'N'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c686cb32",
   "metadata": {},
   "source": [
    "## 6. Explore and Inspect Missing Data\n",
    "\n",
    "Before I clean the dataset, I need to identify which columns contain missing values and how many.  \n",
    "This helps me decide whether to **fill**, **drop**, or **investigate further** depending on the importance of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37553cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values for each column\n",
    "missing = df.isnull().sum()\n",
    "\n",
    "# Filter to show only columns that have missing values, sorted from most to least\n",
    "missing = missing[missing > 0].sort_values(ascending=False)\n",
    "\n",
    "# Create a DataFrame summarizing both the count and percentage of missing values\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Missing %': (missing / len(df) * 100).round(2)\n",
    "})\n",
    "\n",
    "# Display the summary table of missing data\n",
    "print(\"Columns with missing values:\")\n",
    "print(missing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bd453b",
   "metadata": {},
   "source": [
    "## 7. Detect and Clean Leading/Trailing Spaces in String Columns\n",
    "\n",
    "String data can sometimes contain unwanted leading or trailing spaces that cause inconsistencies in analysis and modeling.  \n",
    "This step performs the following actions:\n",
    "\n",
    "1. **Detect** any entries in string columns that have leading or trailing whitespace and display examples to help verify the extent of the issue.\n",
    "2. **Clean** all string columns by stripping these spaces to ensure uniformity.\n",
    "3. **Verify** the cleanup by displaying sample cleaned values for confirmation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6350a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a message to indicate the start of the process\n",
    "print(\"Checking for leading/trailing spaces in string columns...\\n\")\n",
    "\n",
    "# Loop through all columns that are of string (object) type\n",
    "for col in df.select_dtypes(include='object'):\n",
    "    # Identify entries with leading or trailing whitespace to spot data inconsistencies\n",
    "    whitespace_mask = df[col].str.match(r'^\\s+|\\s+$', na=False)\n",
    "    count = whitespace_mask.sum()  # Count how many entries are affected\n",
    "\n",
    "    # If this column has entries with leading/trailing spaces, show samples\n",
    "    if count > 0:\n",
    "        print(f\"Column '{col}' has {count} entries with leading/trailing spaces.\")\n",
    "        print(\"   Sample problematic values:\", df.loc[whitespace_mask, col].unique()[:5])\n",
    "    else:\n",
    "        print(f\"Column '{col}' is clean (no leading/trailing spaces).\")\n",
    "\n",
    "# Inform when the cleanup is beginning\n",
    "print(\"\\nCleaning all string columns by stripping leading and trailing spaces...\\n\")\n",
    "\n",
    "# Remove unwanted whitespace from all string columns to ensure uniformity\n",
    "for col in df.select_dtypes(include='object'):\n",
    "    df[col] = df[col].str.strip()\n",
    "\n",
    "# Confirm cleanup is complete\n",
    "print(\"Cleanup complete. Sample cleaned values for each string column:\")\n",
    "\n",
    "# Show 5 sample cleaned values from each string column\n",
    "for col in df.select_dtypes(include='object'):\n",
    "    print(f\"{col}: {df[col].unique()[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439e4d5f",
   "metadata": {},
   "source": [
    "## 8. Clean the Data + Create Missing Value Flags\n",
    "\n",
    "In this step, I improve the data quality and prepare the dataset for downstream analysis and modeling by performing several critical actions:\n",
    "\n",
    "### Key Steps:\n",
    "- **Drop empty columns**: Remove any columns that are completely missing (all values are `NaN`), as they provide no useful information.\n",
    "- **Create binary missing flags**: For selected categorical columns (e.g. `collision_type`, `police_report_available`, etc.), generate `_missing_flag` columns that indicate if the original value was missing.  \n",
    "  This captures potential *informative missingness* — i.e., missing values that may correlate with fraud.\n",
    "- **Impute non-critical missing values**: Fill missing values in lower-priority columns like `police_report_available` with a default (`'NO'`) to avoid unnecessary row drops.\n",
    "- **Drop rows missing critical data**: Remove rows that are missing essential categorical features such as `incident_type` or `collision_type`, since these are needed for key analyses.\n",
    "- **Parse `policy_csl` coverage limits**: This column contains strings like `\"100/300\"` that represent min/max coverage values. I split this into two new numeric columns:\n",
    "  - `policy_csl_min`: Minimum liability coverage  \n",
    "  - `policy_csl_max`: Maximum liability coverage  \n",
    "  Robust error handling is included to catch and report parsing issues.\n",
    "\n",
    "By combining all these actions into a single cleanup step, I ensure the dataset is both **analytically reliable** and **ready for modeling** — without losing valuable patterns hidden in missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb693a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any columns that contain no data at all\n",
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Impute missing values in 'police_report_available' with 'NO' to retain rows\n",
    "df.fillna({'police_report_available': 'NO'}, inplace=True)\n",
    "\n",
    "# Store original number of rows before dropping critical missing values\n",
    "initial_rows = df.shape[0]\n",
    "\n",
    "# Create binary flags to capture missing values in selected key fields\n",
    "flag_features = ['collision_type', 'police_report_available', 'property_damage', 'authorities_contacted']\n",
    "for col in flag_features:\n",
    "    df[f'{col}_missing_flag'] = df[col].isna().astype(int)\n",
    "\n",
    "# Drop rows missing values in critical categorical features\n",
    "df.dropna(subset=['incident_type', 'collision_type'], inplace=True)\n",
    "\n",
    "# Calculate and report how many rows were dropped\n",
    "dropped_rows = initial_rows - df.shape[0]\n",
    "print(f\"Rows after dropping missing critical categories: {df.shape[0]} (dropped {dropped_rows} rows)\")\n",
    "\n",
    "# Define a helper function to parse 'policy_csl' coverage limits stored as strings like \"100/300\"\n",
    "def parse_policy_csl(csl_str):\n",
    "    try:\n",
    "        parts = csl_str.split('/')\n",
    "        return int(parts[0]), int(parts[1])\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: could not parse policy_csl value '{csl_str}': {e}\")\n",
    "        return (pd.NA, pd.NA)\n",
    "    \n",
    "# Apply parsing function to create separate numeric columns for min and max coverage limits\n",
    "if 'policy_csl' in df.columns:\n",
    "    csl_parsed = df['policy_csl'].apply(lambda x: parse_policy_csl(x) if pd.notna(x) else (pd.NA, pd.NA))\n",
    "    df[['policy_csl_min', 'policy_csl_max']] = pd.DataFrame(csl_parsed.tolist(), index=df.index)\n",
    "    print(\"Parsed 'policy_csl' into 'policy_csl_min' and 'policy_csl_max'.\")\n",
    "\n",
    "    # Display sample of parsed coverage limits alongside original values for verification\n",
    "    print(\"\\nSample of 'policy_csl' parsing results:\")\n",
    "    print(df[['policy_csl', 'policy_csl_min', 'policy_csl_max']].head())\n",
    "\n",
    "# Display new shape of cleaned dataset after these operations\n",
    "print(\"Cleaned data shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c32f32c",
   "metadata": {},
   "source": [
    "## 9. Encode & Format Columns\n",
    "\n",
    "To make the dataset machine readable, I now convert string based fields into consistent numerical and date formats:\n",
    "\n",
    "- Convert `fraud_reported` from `\"Y\"/\"N\"` to binary `1/0`\n",
    "- Format `incident_date` as a proper datetime object for time based analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c60a59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'fraud_reported' from categorical strings ('Y'/'N') to binary numeric values (1/0)\n",
    "df['fraud_reported'] = df['fraud_reported'].map({'Y': 1, 'N': 0})\n",
    "df['fraud_reported'] = df['fraud_reported'].fillna(0).astype(int)\n",
    "\n",
    "# Convert date columns to proper datetime objects for temporal analysis and sorting\n",
    "if 'incident_date' in df.columns:\n",
    "    df['incident_date'] = pd.to_datetime(df['incident_date'], errors='coerce')\n",
    "\n",
    "# Convert 'policy_bind_date' column to datetime format\n",
    "if 'policy_bind_date' in df.columns:\n",
    "    df['policy_bind_date'] = pd.to_datetime(df['policy_bind_date'], errors='coerce')\n",
    "    print(f\"Converted 'policy_bind_date' to datetime with {df['policy_bind_date'].isna().sum()} missing values after conversion.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc5644",
   "metadata": {},
   "source": [
    "## 10. Create a Risk Score Feature\n",
    "\n",
    "I Introduced a simple rule based `risk_score` to help identify potentially fraudulent claims.  \n",
    "Each claim earns a \"risk point\" for meeting one of the following high-risk conditions:\n",
    "\n",
    "- **High claim amount** (greater than \\$10,000)\n",
    "- **Unusual incident time** (between 12:00 AM and 5:00 AM)\n",
    "- **No police report submitted**\n",
    "\n",
    "The final score ranges from `0 = (low risk)` to `3 = (high risk)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8745f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a basic risk score based on three binary risk conditions\n",
    "df['risk_score'] = (\n",
    "    (df['total_claim_amount'] > 10000).astype(int) +                    # 1 point if claim amount exceeds $10,000\n",
    "    (df['incident_hour_of_the_day'].between(0, 5)).astype(int) +        # 1 point if incident occurred between midnight and 5AM\n",
    "    (df['police_report_available'].str.upper() == 'NO').astype(int)     # 1 point if no police report was filed\n",
    ")\n",
    "\n",
    "# Preview relevant fields used in the risk score calculation\n",
    "df[['total_claim_amount', 'incident_hour_of_the_day', 'police_report_available', 'risk_score']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce12e90f",
   "metadata": {},
   "source": [
    "## 11. Final Sanity Check Before Exporting\n",
    "\n",
    "Before saving and exporting the cleaned dataset, I perform a final sanity check to verify:\n",
    "\n",
    "- The overall size of the dataset (number of rows and columns)\n",
    "- The total number of fraud cases (`fraud_reported = 1`)\n",
    "- The total number of non-fraud cases (`fraud_reported = 0`)\n",
    "\n",
    "This helps ensure the data encoding and filtering steps have worked correctly and that the dataset is ready for downstream processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d47356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final sanity check before saving/exporting\n",
    "print(\"Final dataset shape:\", df.shape)\n",
    "print(\"Number of fraud cases:\", df['fraud_reported'].sum())\n",
    "print(\"Number of non-fraud cases:\", (df['fraud_reported'] == 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77336f30",
   "metadata": {},
   "source": [
    "## 12. Save the Cleaned Dataset\n",
    "\n",
    "Now that I've cleaned and preprocessed the data, I'll save it to a **CSV** file.\n",
    "\n",
    "Saving a copy ensures:\n",
    "- You don’t need to re-clean the raw dataset every time.\n",
    "- The data can be reused for **EDA**, modeling, or dashboarding.\n",
    "- It creates an auditable snapshot of your cleaned version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bad53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned DataFrame to a CSV file\n",
    "df.to_csv(cleaned_file, index=False)\n",
    "\n",
    "# Confirm the saved file location\n",
    "print(f\"Cleaned dataset saved to:\\n{cleaned_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf631ff",
   "metadata": {},
   "source": [
    "## 13. Load Cleaned Data into PostgreSQL\n",
    "\n",
    "After saving the cleaned dataset locally, I load it into a **PostgreSQL** table for further analysis and querying.\n",
    "\n",
    "This step enables:\n",
    "- Centralized access to the data via **SQL** tools (e.g., `pgAdmin`, `Tableau`)\n",
    "- Easier integration with reporting dashboards\n",
    "- Scalable querying of clean data without relying on raw **CSVs**\n",
    "\n",
    "The table will be named: `insurance_claims`.\n",
    "If it already exists, it will be **replaced**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5903fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned DataFrame into a PostgreSQL table database (my table name is 'insurance_claims')\n",
    "try:\n",
    "    df.to_sql(\"insurance_claims\", engine, if_exists=\"replace\", index=False)\n",
    "    print(\"Data loaded into PostgreSQL table: 'insurance_claims'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data into PostgreSQL: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026011dd",
   "metadata": {},
   "source": [
    "## 14. Query Fraud vs Non-Fraud Counts\n",
    "\n",
    "To validate that the data was successfully inserted and to get a quick summary of fraud distribution,  \n",
    "I will run a simple **SQL** query to count how many claims were reported as fraud (`1`) vs not fraud (`0`).\n",
    "\n",
    "This helps:\n",
    "- Verify correct encoding of the `fraud_reported` field\n",
    "- Understand basic class balance before modeling\n",
    "- Confirm that data loaded into **PostgreSQL** is accessible and queryable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c6f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL query to count the number of claims by fraud label\n",
    "query = \"\"\"\n",
    "SELECT fraud_reported, COUNT(*) as count\n",
    "FROM insurance_claims\n",
    "GROUP BY fraud_reported;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and display results\n",
    "fraud_summary = pd.read_sql(query, engine)\n",
    "fraud_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6ba096",
   "metadata": {},
   "source": [
    "# ETL Complete\n",
    "\n",
    "Cleaned data saved locally as **CSV**  \n",
    "Data loaded into **PostgreSQL** (pgAdmin4) under table: `insurance_claims`  \n",
    "Fraud summary query executed successfully\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps:\n",
    "- Exploratory Data Analysis **(EDA)**\n",
    "- Feature Engineering\n",
    "- Model Training **(Fraud Prediction)**\n",
    "- Reporting & Dashboarding **(Tableau)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
