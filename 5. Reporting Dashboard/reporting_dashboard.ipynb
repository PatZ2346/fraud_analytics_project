{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e40cf6b3",
   "metadata": {},
   "source": [
    "# Reporting Dashboard Setup for Tableau\n",
    "\n",
    "This notebook prepares the final engineered dataset for Tableau visualization by loading it into PostgreSQL. Tableau will then connect to this data source to build interactive fraud detection dashboards, enabling stakeholders to explore fraud trends, risk scores, and claim characteristics with ease.\n",
    "\n",
    "> **PLEASE READ BEFORE PROCEEDING:**  \n",
    "> The steps from 1-3 are for users with **Tableau Desktop** only and not recommended for users with **Tableau Public**.  \n",
    "> For **Tableau Public** users, please refer to steps 4.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca12d069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports and file path setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Imports essential libraries and Setup\n",
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "from getpass import getpass  # For secure password input\n",
    "\n",
    "# Project directory and engineered features file path\n",
    "project_dir = r\"C:\\Users\\Cloud\\OneDrive\\Desktop\\Fraud_Analytics_Project\"\n",
    "feature_file = os.path.join(project_dir, \"data\", \"features\", \"engineered_insurance_claims.csv\")\n",
    "print(\"Imports and file path setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec890cad",
   "metadata": {},
   "source": [
    "### 1. PostgreSQL Connection Setup\n",
    "\n",
    "I created a secure connection to the PostgreSQL database where Tableau will fetch the data.  \n",
    "Using `getpass()` avoids hardcoding sensitive passwords in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03a5e8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL engine created.\n"
     ]
    }
   ],
   "source": [
    "# Securely prompt for PostgreSQL password\n",
    "pg_user = \"postgres\"\n",
    "pg_password = getpass(\"Enter PostgreSQL password: \")\n",
    "pg_host = \"localhost\"\n",
    "pg_port = 5432\n",
    "pg_dbname = \"fraud_analytics\"\n",
    "\n",
    "# Create SQLAlchemy engine for PostgreSQL connection\n",
    "engine = create_engine(f\"postgresql+psycopg2://{pg_user}:{pg_password}@{pg_host}:{pg_port}/{pg_dbname}\")\n",
    "print(\"PostgreSQL engine created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e10d6d",
   "metadata": {},
   "source": [
    "### 2. Load Engineered Data into PostgreSQL\n",
    "\n",
    "Load the final feature-engineered dataset into a PostgreSQL table called `tableau_insurance_claims`.  \n",
    "Using `if_exists='replace'` ensures the table refreshes with the latest data on each run, keeping Tableau dashboards up-to-date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dedd773f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 records into PostgreSQL table: tableau_insurance_claims\n"
     ]
    }
   ],
   "source": [
    "# Drop the view if it exists using SQLAlchemy's `text()`\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"DROP VIEW IF EXISTS v_fraud_summary;\"))  # Wrapped in text()\n",
    "    conn.commit()  # Commit the transaction\n",
    "\n",
    "# Load the engineered dataset into a DataFrame\n",
    "df = pd.read_csv(feature_file)\n",
    "\n",
    "# Replace the PostgreSQL table\n",
    "df.to_sql(\"tableau_insurance_claims\", engine, if_exists=\"replace\", index=False)\n",
    "print(f\"Loaded {df.shape[0]} records into PostgreSQL table: tableau_insurance_claims\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f1898c",
   "metadata": {},
   "source": [
    "### 3. For Tableau Desktop Users: Manually Create PostgreSQL View\n",
    "\n",
    "To simplify your data connection and improve dashboard performance in Tableau Desktop, create a PostgreSQL view that organizes key fraud analytics columns.\n",
    "\n",
    "### Follow these steps to create the view using pgAdmin4:\n",
    "\n",
    "1. **Open pgAdmin4** on your computer and connect to your PostgreSQL server.\n",
    "\n",
    "2. In the left sidebar, navigate to your database:\n",
    "   - Expand **Servers** → your server name → **Databases** → `fraud_analytics` (or your database name).\n",
    "\n",
    "3. Right-click on **Schemas** → **public** → **Views**, and select **Create** → **View...**\n",
    "\n",
    "4. In the **Create - View** dialog:\n",
    "   - Enter the view name as: `v_fraud_summary`\n",
    "   - Click the **Definition** tab or section.\n",
    "\n",
    "5. Paste the following SQL query into the **View Definition** box:\n",
    "\n",
    "    ```sql\n",
    "    CREATE OR REPLACE VIEW v_fraud_summary AS\n",
    "    SELECT\n",
    "        fraud_reported,\n",
    "        total_claim_amount,\n",
    "        risk_score,\n",
    "        fraud_weight,\n",
    "        incident_year,\n",
    "        incident_month,\n",
    "        incident_dayofweek,\n",
    "        incident_is_weekend,\n",
    "        \"incident_type_PARKED CAR\",\n",
    "        \"incident_type_SINGLE VEHICLE COLLISION\",\n",
    "        \"incident_type_VEHICLE THEFT\",\n",
    "        \"collision_type_REAR COLLISION\",\n",
    "        \"collision_type_SIDE COLLISION\",\n",
    "        \"police_report_available_YES\"\n",
    "    FROM\n",
    "    tableau_insurance_claims;\n",
    "    ```\n",
    "\n",
    "6. Click **Save** or **OK** to create the view.\n",
    "\n",
    "7. To verify, expand the **Views** node under your database schema, and confirm `v_fraud_summary` appears.\n",
    "\n",
    "8. Now, in Tableau, you can connect directly to this view `v_fraud_summary` instead of the full table for easier querying and cleaner dashboards.\n",
    "\n",
    "---\n",
    "\n",
    "> Notes:  \n",
    "> Creating this view does **not** duplicate the data (as tested), it simply defines a saved SQL query that Tableau can use.  \n",
    "> If data updates frequently, the view will always reflect the latest table data.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72416c87",
   "metadata": {},
   "source": [
    "### 4. Export Data for Tableau Public\n",
    "\n",
    "Now for users who only have Tableau Public and since the public version does **not** support direct database connections like PostgreSQL, follow these steps to export the data as a CSV file that you can load into Tableau Public:\n",
    "\n",
    "1. **Export data from PostgreSQL to CSV:**\n",
    "   - This notebook already saves the cleaned and engineered data as a CSV (`engineered_insurance_claims.csv`).\n",
    "   - If you want to export the latest data from the database, you can also run a SQL query in pgAdmin or use a Python script to export the table or view as CSV.\n",
    "\n",
    "2. **Load CSV into Tableau Public:**\n",
    "   - Open Tableau Public.\n",
    "   - Click **“Text File”** under **Connect** on the left sidebar.\n",
    "   - Browse and select the CSV file (`engineered_insurance_claims.csv`) exported by this project.\n",
    "   - Once loaded, you can start building your dashboards and visualizations.\n",
    "\n",
    "3. **Keep your CSV updated:**\n",
    "   - For good practice, whenever new data or model outputs are available, rerun the export process to refresh your CSV file for Tableau Public.\n",
    "\n",
    "---\n",
    "\n",
    ">**Tip:**  \n",
    ">If you have Tableau Desktop or upgrade later, you can connect directly to the PostgreSQL database (please refer back from steps 1-3 for live data refreshes and more advanced workflows).\n",
    "\n",
    "---\n",
    "\n",
    "**Summary:**  \n",
    "- Export data as CSV from PostgreSQL or this notebook.  \n",
    "- Load CSV into Tableau Public.  \n",
    "- Create and publish dashboards from the static CSV data.\n",
    "\n",
    "---\n",
    "\n",
    "> **NOTE**  \n",
    ">The code below is when:  \n",
    "> - You make further updates or merges after the original CSV.  \n",
    "> - You want to create a separate CSV specifically for dashboarding (maybe with selected columns or formatting).  \n",
    "> - You want to automate refreshing the dashboard data by re-exporting after new model runs.  \n",
    "\n",
    "`Therefore, It’s totally safe to run the code every time you rerun the notebook!  \n",
    "It simply overwrites (or creates) the CSV file with the latest data — no risk of data corruption or issues.  \n",
    "In fact, running it as part of your full pipeline ensures your Tableau Public CSV is always up-to-date after any data or model changes.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "323ce2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset exported to CSV for Tableau Public: C:\\Users\\Cloud\\OneDrive\\Desktop\\Fraud_Analytics_Project\\data\\tableau_insurance_claims_final.csv\n"
     ]
    }
   ],
   "source": [
    "# Define export path for Tableau Public\n",
    "export_csv_path = os.path.join(project_dir, \"data\", \"tableau_insurance_claims_final.csv\")\n",
    "\n",
    "# Export DataFrame to CSV\n",
    "df.to_csv(export_csv_path, index=False)\n",
    "\n",
    "print(f\"Dataset exported to CSV for Tableau Public: {export_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072abc60",
   "metadata": {},
   "source": [
    "### 5. Dashboard Ideas for Fraud Analytics\n",
    "\n",
    "- **Total Claim Amount** by Fraud Status  \n",
    "- **Average Risk Score** by Incident Type  \n",
    "- Fraud **Trends Over Time** (Monthly, Weekly, Daily)  \n",
    "- Heatmap of **Fraud Frequency** by Hour of Day vs Collision Type  \n",
    "- Bar chart showing **Fraud Percentage** by Police Report Availability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
